AWSTemplateFormatVersion: "2010-09-09"
Description: Docker Compose test elastic stack
Parameters:
  VpcId:
    Description: ID of the VPC onto which to launch the application
    Type: AWS::EC2::VPC::Id
    Default: "vpc-037080e34cae35ead"
  VpcSubnets:
    Type: List<AWS::EC2::Subnet::Id>
    Default: subnet-014214c87e997c42c
  KeyName:
    Type: AWS::EC2::KeyPair::KeyName
    Description: Key for SSH access
    ConstraintDescription: It must be a valid Key
  EC2InstanceType:
    Description: EC2 instance type
    Type: String
    Default: t2.large
    AllowedValues:
      - t2.medium
      - t2.large
      - t2.xlarge
  ImageId:
    Description: EC2 image id
    Type: String
    Default: ami-0119aa4d67e59007c
    AllowedValues:
      - ami-0119aa4d67e59007c
      - ami-05b0d50be1ff1f6ae
      - ami-0975ce566eec139c3
      - ami-0328aad0f6218c429
     
Resources:
  SrvSG:
    Type: AWS::EC2::SecurityGroup
    Properties:
      GroupDescription: Access to elastic stack
      GroupName: !Sub
        - ${CFormationName}-elastic-Docker-SG
        - { CFormationName: !Ref 'AWS::StackName' }
      Tags:
        -
          Key: "Name"
          Value: !Sub
            - ${CFormationName}-elastic-Docker-SG
            - { CFormationName: !Ref 'AWS::StackName' }
      VpcId: !Ref VpcId
      SecurityGroupIngress:
       #SSH
       - IpProtocol: tcp
         Description: SSH 
         FromPort: 22
         ToPort: 22
         CidrIp: 0.0.0.0/0
       #ICMP  
       - IpProtocol: icmp
         Description: ICMP
         FromPort: 8
         ToPort: -1
         CidrIp: 0.0.0.0/0
       #Elasticsearch
       - IpProtocol: tcp
         Description: Elasticsearch
         FromPort: 9200 
         ToPort: 9200
         CidrIp: 0.0.0.0/0
       - IpProtocol: tcp
         Description: Elasticsearch
         FromPort: 9201
         ToPort: 9201
         CidrIp: 0.0.0.0/0
       - IpProtocol: tcp
         Description: Elasticsearch
         FromPort: 9202 
         ToPort: 9202
         CidrIp: 0.0.0.0/0
       - IpProtocol: tcp
         Description: Elasticsearch
         FromPort: 9300
         ToPort: 9300
         CidrIp: 0.0.0.0/0
       #Logstash
       - IpProtocol: tcp
         Description: Logstash
         FromPort: 5000
         ToPort: 5000
         CidrIp: 0.0.0.0/0
       - IpProtocol: tcp
         Description: Logstash
         FromPort: 5044 
         ToPort: 5044
         CidrIp: 0.0.0.0/0
       - IpProtocol: tcp
         Description: Logstash
         FromPort: 9600 
         ToPort: 9600
         CidrIp: 0.0.0.0/0
       - IpProtocol: udp
         Description: Logstash
         FromPort: 25826
         ToPort: 25826
         CidrIp: 0.0.0.0/0
       #Kibana
       - IpProtocol: tcp
         Description: Kibana
         FromPort: 5601
         ToPort: 5601
         CidrIp: 0.0.0.0/0
       #Nginx
       - IpProtocol: tcp
         Description: Nginx for Kibana
         FromPort: 80 
         ToPort: 80
         CidrIp: 0.0.0.0/0
       #Cerebro
       - IpProtocol: tcp
         Description: Cerebro
         FromPort: 9000
         ToPort: 9000
         CidrIp: 0.0.0.0/0

  Eth0:
    Type: AWS::EC2::NetworkInterface
    Properties:
       Tags:
       - Key: Name
         Value: Interface Eth0
       Description: Interface Eth0
       SourceDestCheck: 'false'
       SubnetId: subnet-014214c87e997c42c
       GroupSet: 
       - !Ref SrvSG

  DockerEC2elastic:
    Type: AWS::EC2::Instance
    Properties:
      AvailabilityZone:
        Fn::Select: 
          - 0
          - Fn::GetAZs: ""
      InstanceType: !Ref EC2InstanceType
      KeyName: !Ref KeyName
      ImageId: !Ref ImageId
#      SubnetId: subnet-014214c87e997c42c
    #  SecurityGroups: 
    #    - !Ref SrvSG
#      SecurityGroupIds:
 #       - !GetAtt "SrvSG.GroupId"
      Tags:
        - 
          Key: Name
          Value: !Sub
            - ${CFormationName}-Dockerized-ELK-Stack-Srv
            - { CFormationName: !Ref 'AWS::StackName' }
      NetworkInterfaces:
        - NetworkInterfaceId: !Ref 'Eth0'
          DeviceIndex: '0'
      UserData:
        Fn::Base64: !Sub |
          #!/bin/bash
          #Install Docker
          sudo yum update -y
          sudo amazon-linux-extras install docker
          sudo service docker start
          sudo systemctl enable docker.service
          sudo usermod -a -G docker ec2-user
          #Install docker compose
          sudo curl -L "https://github.com/docker/compose/releases/download/1.25.0/docker-compose-$(uname -s)-$(uname -m)" -o /usr/local/bin/docker-compose
          sudo chmod +x /usr/local/bin/docker-compose
          sudo ln -s /usr/local/bin/docker-compose /usr/bin/docker-compose
          #Create directories 
          mkdir -p /dockerdata/elasticsearch/volumemount1
          mkdir -p /dockerdata/elasticsearch/volumemount2
          mkdir -p /dockerdata/elasticsearch/volumemount3
          mkdir -p /dockerdata/logstash/pipeline/conf.d
          mkdir -p /dockerdata/nginx
          sudo chmod 777 /dockerdata/elasticsearch/volumemount1
          sudo chmod 777 /dockerdata/elasticsearch/volumemount2
          sudo chmod 777 /dockerdata/elasticsearch/volumemount3
          sudo chmod 777 /etc/sysctl.conf
          echo "vm.max_map_count=262144" >> /etc/sysctl.conf
          sudo chmod 644 /etc/sysctl.conf
          sysctl --system
          #Create nginx conf file
          cat > "/dockerdata/nginx/nginx.conf" << EOF
          events {
            worker_connections  1024;
          }          
          http {
            server {
              listen 9200;
          
              location / {
                proxy_pass      http://es01:9200/;
                auth_basic "Elasticsearch";
                auth_basic_user_file /etc/nginx/.htpasswd;
              }
            }
            server {
              listen 80;
          
              location / {
                 proxy_pass      http://kibana:5601/;
              }
            }
          }
          EOF
          #Create logstash conf file
          cat > "/dockerdata/logstash/pipeline/conf.d/logstash.conf" << EOF
          input {
            beats {
              port => 5044
            }
          }
          
          output {
            if "sysmessages" in [tags] {
              elasticsearch {
                hosts => "es01:9200"
                manage_template => false
                index => "sysmessages-%{+YYYY.MM}"
              }
            }
            else if "haproxy" in [tags] {
              elasticsearch {
                hosts => "es01:9200"
                manage_template => false
                index => "haproxy-%{+YYYY.MM}"
              }
            }
          }
          EOF
          #Create docker compose file          
          cat > "/home/ec2-user/docker-compose.yml" << EOF
          version: '3'
          
          networks:
            elastic:
          
          volumes:
            es01:
              driver: local
            es02:
              driver: local
            es03:
              driver: local

          services:
            es01:
              image: docker.elastic.co/elasticsearch/elasticsearch:7.5.0
              container_name: es01
              environment:
                - node.name=es01
                - cluster.name=es-docker-cluster
                - discovery.seed_hosts=es02,es03
                - cluster.initial_master_nodes=es01,es02,es03
                - bootstrap.memory_lock=true
                - "ES_JAVA_OPTS=-Xms512m -Xmx512m"
              ulimits:
                memlock:
                  soft: -1
                  hard: -1
                nofile:
                  soft: 65536
                  hard: 65536
              volumes:
                - /dockerdata/elasticsearch/volumemount1:/usr/share/elasticsearch/data
              ports:
                - 9200:9200
              networks:
                - elastic
          
            es02:
              image: docker.elastic.co/elasticsearch/elasticsearch:7.5.0
              container_name: es02
              environment:
                - node.name=es02
                - cluster.name=es-docker-cluster
                - discovery.seed_hosts=es01,es03
                - cluster.initial_master_nodes=es01,es02,es03
                - bootstrap.memory_lock=true
                - "ES_JAVA_OPTS=-Xms512m -Xmx512m"
              ulimits:
                memlock:
                  soft: -1
                  hard: -1
                nofile:
                  soft: 65536
                  hard: 65536
              volumes:
                - /dockerdata/elasticsearch/volumemount2:/usr/share/elasticsearch/data
              ports:
                - 9201:9201
              networks:
                - elastic
          
            es03:
              image: docker.elastic.co/elasticsearch/elasticsearch:7.5.0
              container_name: es03
              environment:
                - node.name=es03
                - cluster.name=es-docker-cluster
                - discovery.seed_hosts=es01,es02
                - cluster.initial_master_nodes=es01,es02,es03
                - bootstrap.memory_lock=true
                - "ES_JAVA_OPTS=-Xms512m -Xmx512m"
              ulimits:
                memlock:
                  soft: -1
                  hard: -1
                nofile:
                  soft: 65536
                  hard: 65536
              volumes:
                - /dockerdata/elasticsearch/volumemount3:/usr/share/elasticsearch/data
              ports:
                - 9202:9202
              networks:
                - elastic
          
            logstash:
              image: docker.elastic.co/logstash/logstash-oss:7.5.0
              container_name: logstash
              depends_on:
              - es01
              - es02
              - es03
              networks:
                elastic: null
              ports:
              - "5044:5044"
              - "5000:5000"
              - "25826:25826/udp"
              restart: unless-stopped
              volumes:
              - /dockerdata/logstash/pipeline/conf.d:/usr/share/logstash/pipeline:rw
          
            kibana:
              depends_on:
              - es01
              environment:
                ELASTICSEARCH_URL: http://es01:9200
                ELASTICSEARCH_HOSTS: http://es01:9200
              container_name: kibana
              image: docker.elastic.co/kibana/kibana-oss:7.5.0
              networks:
                elastic: null
              ports:
              - 5601:5601
              restart: unless-stopped
          
            nginx:
              image: nginx:latest
              container_name: nginx
              networks:
                elastic: null
              ports:
                - "80:80"
              volumes:
                - /dockerdata/nginx/nginx.conf:/etc/nginx/nginx.conf:rw
              
            cerebro:
              image: yannart/cerebro:latest
              ports:
                - "9000:9000"
              networks:
                elastic: null
          EOF
          #Run Docker Compose
          cd /home/ec2-user
          sudo docker-compose up -d
          docker start nginx
          #Set up filebeat on local host
          curl -L -O https://artifacts.elastic.co/downloads/beats/filebeat/filebeat-7.5.1-x86_64.rpm && sudo rpm -vi filebeat-7.5.1-x86_64.rpm
          systemctl start filebeat && systemctl enable filebeat
          mv /etc/filebeat/filebeat.yml /etc/filebeat/filebeat.yml.original
          cat > "/etc/filebeat/filebeat.yml" << EOF
          filebeat.inputs:
            - type: log
              paths:
                - /var/log/haproxy.log
              tags: ["haproxy"]
            
            - type: log
              paths:
                - /var/log/secure
                - /var/log/cron
                - /var/log/messages
              tags: ["sysmessages"]
            
          output.logstash:
            hosts: ["localhost:5044"]
          EOF
          systemctl restart filebeat.service
          systemctl enable filebeat.service

  DockerEC2Filebeat1:
    Type: AWS::EC2::Instance
    Properties:
      AvailabilityZone:
        Fn::Select: 
          - 0
          - Fn::GetAZs: ""
      InstanceType: t2.micro
      KeyName: !Ref KeyName
      ImageId: !Ref ImageId
      SubnetId: subnet-014214c87e997c42c
      SecurityGroupIds:
        - !GetAtt "SrvSG.GroupId"
      Tags:
        - 
          Key: Name
          Value: !Sub 
            - ${CFormationName}-Filebeat-Srv
            - { CFormationName: !Ref 'AWS::StackName' }
      UserData:
        Fn::Base64: !Sub |
          #!/bin/bash
          #Set up filebeat on local host
          sudo curl -L -O https://artifacts.elastic.co/downloads/beats/filebeat/filebeat-7.5.1-x86_64.rpm && sudo rpm -vi filebeat-7.5.1-x86_64.rpm
          sudo systemctl start filebeat && systemctl enable filebeat
          mv /etc/filebeat/filebeat.yml /etc/filebeat/filebeat.yml.original
          cat > "/etc/filebeat/filebeat.yml" << EOF
          filebeat.inputs:
            - type: log
              paths:
                - /var/log/haproxy.log
              tags: ["haproxy"]
            
            - type: log
              paths:
                - /var/log/secure
                - /var/log/cron
                - /var/log/messages
              tags: ["sysmessages"]
            
          output.logstash:
            hosts: ["10.174.21.110:5044"]
          EOF
          sudo systemctl restart filebeat.service
          sudo systemctl enable filebeat.service
          #Rsyslog installation
          yum -y install rsyslog
          sudo systemctl start rsyslog && systemctl enable rsyslog
          #HAProxy logging set up
          sudo yum -y install haproxy
          sudo systemctl start haproxy && systemctl enable haproxy
          cat > "/etc/rsyslog.d/haproxylog.conf" << EOF
          # Create an additional socket in haproxy's chroot in order to allow logging via
          # /dev/log to chroot'ed HAProxy processes
          \$AddUnixListenSocket /var/lib/haproxy/dev/log
          
          # Send HAProxy messages to a dedicated logfile
          if \$programname startswith 'haproxy' then /var/log/haproxy.log
          &~
          EOF
          sudo systemctl restart rsyslog
          sudo systemctl restart haproxy
          
          
          









          














    